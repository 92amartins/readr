% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/tokenizer.R
\name{Tokenizers}
\alias{Tokenizers}
\alias{tokenizer_csv}
\alias{tokenizer_fwf}
\alias{tokenizer_line}
\title{Tokenizers.}
\usage{
tokenizer_csv(na = "NA")

tokenizer_line()

tokenizer_fwf(begin, end, na = "NA")
}
\arguments{
\item{na}{String to use for missing values.}

\item{begin,end}{Begin and end offsets for each file. These are C++
offsets so the first column is column zero, and the ranges are
[begin, end) (i.e inclusive-exclusive).}
}
\description{
Explicitly create tokenizer objects. Usually you will not call these
function, but will instead use one of the use friendly wrappers like
\code{read_csv}.
}
\examples{
tokenizer_csv()
}
\keyword{internal}

